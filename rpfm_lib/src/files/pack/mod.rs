//---------------------------------------------------------------------------//
// Copyright (c) 2017-2022 Ismael Gutiérrez González. All rights reserved.
//
// This file is part of the Rusted PackFile Manager (RPFM) project,
// which can be found here: https://github.com/Frodo45127/rpfm.
//
// This file is licensed under the MIT license, which can be found here:
// https://github.com/Frodo45127/rpfm/blob/master/LICENSE.
//---------------------------------------------------------------------------//

/*!
Module with all the code to interact with PackFiles.

This module contains all the code related with PackFiles. If you want to do anything with a PackFile,
this is the place you have to come.

Also, something to take into account. RPFM supports PackFile compression/decompression and decryption,
and that is handled automagically by RPFM. All the data you'll ever see will be decompressed/decrypted,
so you don't have to worry about that.
!*/

use bitflags::bitflags;
use getset::*;
use rayon::prelude::*;
use serde_derive::{Serialize, Deserialize};
use serde_json::{from_slice, to_string_pretty};
use itertools::Itertools;

use std::collections::{BTreeMap, HashMap, HashSet};
use std::fs::File;
use std::io::{BufReader, BufWriter, Cursor, SeekFrom, Write};
use std::path::{Path, PathBuf};
use std::str::FromStr;

use crate::binary::{ReadBytes, WriteBytes};
use crate::compression::Compressible;
use crate::error::{RLibError, Result};
use crate::files::{Container, ContainerPath, Decodeable, DecodeableExtraData, Encodeable, EncodeableExtraData, FileType, Loc, RFile, table::DecodedData};
use crate::games::{GameInfo, pfh_file_type::PFHFileType, pfh_version::PFHVersion};
use crate::utils::{current_time, last_modified_time_from_file};

use super::RFileDecoded;

#[cfg(test)]
mod pack_test;
mod pack_versions;

pub const EXTENSION: &str = ".pack";

/// These are the different Preamble/Id the PackFiles can have.
const MFH_PREAMBLE: &str = "MFH"; // Weird format of some packs downloaded from Steam.

/// This one is the path in a `PackFile` where all the maps generated by Terry end up.
const TERRY_MAP_PATH: &str = "terrain/tiles/battle/_assembly_kit";

/// This one is the name of the main BMD data file used by maps exported from Terry.
const DEFAULT_BMD_DATA: &str = "bmd_data.bin";

/// These three hints are necessary for the map patching function.
const FORT_PERIMETER_HINT: &[u8; 18] = b"AIH_FORT_PERIMETER";
const DEFENSIVE_HILL_HINT: &[u8; 18] = b"AIH_DEFENSIVE_HILL";
const SIEGE_AREA_NODE_HINT: &[u8; 19] = b"AIH_SIEGE_AREA_NODE";

pub const RESERVED_NAME_DEPENDENCIES_MANAGER: &str = "dependencies_manager.rpfm_reserved";
pub const RESERVED_NAME_EXTRA_PACKFILE: &str = "extra_packfile.rpfm_reserved";
pub const RESERVED_NAME_SETTINGS: &str = "settings.rpfm_reserved";
pub const RESERVED_NAME_SETTINGS_EXTRACTED: &str = "settings.rpfm_reserved.json";
pub const RESERVED_NAME_NOTES: &str = "notes.rpfm_reserved";
pub const RESERVED_NAME_NOTES_EXTRACTED: &str = "notes.rpfm_reserved.md";

/// This is the list of ***Reserved PackedFile Names***. They're packedfile names used by RPFM for special purposes.
pub const RESERVED_RFILE_NAMES: [&str; 3] = [RESERVED_NAME_EXTRA_PACKFILE, RESERVED_NAME_SETTINGS, RESERVED_NAME_NOTES];

const AUTHORING_TOOL_CA: &str = "CA_TOOL";
const AUTHORING_TOOL_RPFM: &str = "RPFM";
const AUTHORING_TOOL_SIZE: u32 = 8;

bitflags! {

    /// This represents the bitmasks a PackFile can have applied to his type.
    ///
    /// Keep in mind that this lib supports decoding PackFiles with any of these flags enabled,
    /// but it only supports enconding for the `HAS_INDEX_WITH_TIMESTAMPS` flag.
    #[derive(Serialize, Deserialize)]
    pub struct PFHFlags: u32 {

        /// Used to specify that the header of the PackFile is extended by 20 bytes. Used in Arena.
        const HAS_EXTENDED_HEADER       = 0b0000_0001_0000_0000;

        /// Used to specify that the PackedFile Index is encrypted. Used in Arena.
        const HAS_ENCRYPTED_INDEX       = 0b0000_0000_1000_0000;

        /// Used to specify that the PackedFile Index contains a timestamp of every PackFile.
        const HAS_INDEX_WITH_TIMESTAMPS = 0b0000_0000_0100_0000;

        /// Used to specify that the PackedFile's data is encrypted. Seen in `music.pack` PackFiles and in Arena.
        const HAS_ENCRYPTED_DATA        = 0b0000_0000_0001_0000;
    }
}

//---------------------------------------------------------------------------//
//                              Enum & Structs
//---------------------------------------------------------------------------//

/// This `Struct` stores the data of the PackFile in memory, along with some extra data needed to manipulate the PackFile.
#[derive(Debug, Clone, PartialEq, Getters, MutGetters, Setters, Default, Serialize, Deserialize)]
#[getset(get = "pub", get_mut = "pub", set = "pub")]
pub struct Pack {

    /// The path of the PackFile on disk, if exists. If not, then this should be empty.
    disk_file_path: String,
    disk_file_offset: u64,
    local_timestamp: u64,

    compress: bool,

    header: PackHeader,


    /// The list of PackFiles this PackFile requires to be loaded before himself when starting the game.
    ///
    /// In other places, we refer to this as the `Dependency List`.
    dependencies: Vec<String>,

    /// The list of PackedFiles this PackFile contains.
    files: HashMap<String, RFile>,

    /// Notes added to the PackFile. Exclusive of this lib.
    notes: String,

    /// Settings stored in the PackFile itself, to be able to share them between installations.
    settings: PackSettings,
}

#[derive(Debug, Clone, PartialEq, Eq, Default, Getters, Setters, Serialize, Deserialize)]
#[getset(get = "pub", set = "pub")]
pub struct PackHeader {

    /// The version of the PackFile.
    pfh_version: PFHVersion,

    /// The type of the PackFile.
    pfh_file_type: PFHFileType,

    /// The bitmasks applied to the PackFile.
    bitmask: PFHFlags,

    /// The timestamp of the last time the PackFile was saved.
    internal_timestamp: u64,

    /// Game version this Pack is intended for. This usually triggers the "outdated mod" warning in the launcher if it doesn't match the current exe version.
    game_version: u32,

    /// Build number of the game.
    build_number: u32,

    /// Tool that created the PackFile. Max 8 characters, 00-padded.
    authoring_tool: String,

    /// Extra subheader data, in case it's used in the future.
    extra_subheader_data: Vec<u8>,
}

/// This struct hold PackFile-specific settings.
#[derive(Clone, Debug, PartialEq, Eq, Default, Serialize, Deserialize)]
pub struct PackSettings {

    /// For multi-line text.
    pub settings_text: BTreeMap<String, String>,

    /// For single-line text.
    pub settings_string: BTreeMap<String, String>,

    /// For bool values.
    pub settings_bool: BTreeMap<String, bool>,

    /// For integer values.
    pub settings_number: BTreeMap<String, i32>,
}

//---------------------------------------------------------------------------//
//                           Structs Implementations
//---------------------------------------------------------------------------//

impl Container for Pack {

    /// This method allows us to extract the metadata associated to the provided container as `.json` or `.md` files.
    ///
    /// [Pack] implementation extracts the [PackSettings] of the provided Pack and its associated notes.
    fn extract_metadata(&mut self, destination_path: &Path) -> Result<()> {
        if !self.notes.is_empty() {
            let mut data = vec![];
            data.write_string_u8(&self.notes)?;
            let path = destination_path.join(RESERVED_NAME_NOTES_EXTRACTED);
            let mut file = BufWriter::new(File::create(path)?);
            file.write_all(&data)?;
            file.flush()?;
        }

        let mut data = vec![];
        data.write_all(to_string_pretty(&self.settings)?.as_bytes())?;
        data.extend_from_slice(b"\n"); // Add newline to the end of the file

        let path = destination_path.join(RESERVED_NAME_SETTINGS_EXTRACTED);
        let mut file = BufWriter::new(File::create(path)?);
        file.write_all(&data)?;
        file.flush()?;

        Ok(())
    }

    fn insert(&mut self, mut file: RFile) -> Result<ContainerPath> {

        // Filter out special files, so we only leave the normal files in.
        let path_container = file.path_in_container();
        let path = file.path_in_container_raw();
        if path == RESERVED_NAME_NOTES_EXTRACTED {
            let mut data = Cursor::new(file.encode(&None, false, false, true)?.unwrap());
            let data_len = data.len()?;
            if let Ok(data) = data.read_string_u8(data_len as usize) {
                self.notes = data;
            }
        } else if path == RESERVED_NAME_SETTINGS_EXTRACTED {
            self.settings = PackSettings::load(&file.encode(&None, false, false, true)?.unwrap())?
        }

        // If it's not filtered out, add it to the Pack.
        else {
            self.files.insert(path.to_owned(), file);
        }

        Ok(path_container)
    }

    fn disk_file_path(&self) -> &str {
       &self.disk_file_path
    }

    fn files(&self) -> &HashMap<String, RFile> {
        &self.files
    }

    fn files_mut(&mut self) -> &mut HashMap<String, RFile> {
        &mut self.files
    }

    fn disk_file_offset(&self) -> u64 {
       self.disk_file_offset
    }

    fn internal_timestamp(&self) -> u64 {
       self.header.internal_timestamp
    }

    fn local_timestamp(&self) -> u64 {
       self.local_timestamp
    }

    /// This function allows you to *move* any RFile of folder of RFiles from one folder to another.
    ///
    /// It returns a list with all the new [ContainerPath].
    fn move_path(
        &mut self,
        source_path: ContainerPath,
        destination_path: ContainerPath,
    ) -> Result<Vec<ContainerPath>> {
        match source_path {
            ContainerPath::File(source_path) => match destination_path {
                ContainerPath::File(destination_path) => {
                    if RESERVED_RFILE_NAMES.contains(&&*destination_path) {
                        return Err(RLibError::ReservedFiles);
                    }

                    if destination_path.is_empty() {
                        return Err(RLibError::EmptyDestiny);
                    }

                    let mut moved = self.files_mut().remove(&source_path).ok_or_else(|| RLibError::FileNotFound(source_path.to_string()))?;
                    moved.set_path_in_container_raw(&destination_path);
                    self.insert(moved).map(|x| vec![x; 1])
                },
                ContainerPath::Folder(_) => unreachable!(),
            },
            ContainerPath::Folder(source_path) => match destination_path {
                ContainerPath::File(_) => unreachable!(),
                ContainerPath::Folder(destination_path) => {
                    if destination_path.is_empty() {
                        return Err(RLibError::EmptyDestiny);
                    }

                    let moved_paths = self.files()
                        .par_iter()
                        .filter_map(|(path, _)| if path.starts_with(&source_path) { Some(path.to_owned()) } else { None })
                        .collect::<Vec<_>>();
                    let moved = moved_paths.iter().filter_map(|x| self.files_mut().remove(x)).collect::<Vec<_>>();
                    let mut new_paths = Vec::with_capacity(moved.len());
                    for mut moved in moved {
                        let path = moved.path_in_container_raw().replacen(&source_path, &destination_path, 1);
                        moved.set_path_in_container_raw(&path);
                        new_paths.push(self.insert(moved)?);
                    }

                    Ok(new_paths)
                },
            },
        }
    }
}

impl Decodeable for Pack {

    fn decode<R: ReadBytes>(data: &mut R, extra_data: &Option<DecodeableExtraData>) -> Result<Self> {
        Self::read(data, extra_data)
    }
}

impl Encodeable for Pack {

    fn encode<W: WriteBytes>(&mut self, buffer: &mut W, extra_data: &Option<EncodeableExtraData>) -> Result<()> {
        self.write(buffer, extra_data)
    }
}

/// Implementation of `Pack`.
impl Pack {

    /// This function creates a new empty Pack with a specific PFHVersion.
    pub fn new_with_version(pfh_version: PFHVersion) -> Self {
        let mut pack = Self::default();
        pack.header.pfh_version = pfh_version;
        pack
    }

    /// This function creates a new empty Pack with a name and a specific PFHVersion.
    pub fn new_with_name_and_version(name: &str, pfh_version: PFHVersion) -> Self {
        let mut pack = Self::default();
        pack.header.pfh_version = pfh_version;
        pack.disk_file_path = name.to_owned();
        pack
    }

    /// This function tries to read a `Pack` from raw data.
    ///
    /// If `lazy_load` is false, the data of all the files inside the `Pack` will be preload to memory.
    fn read<R: ReadBytes>(data: &mut R, extra_data: &Option<DecodeableExtraData>) -> Result<Self> {
        let extra_data = extra_data.as_ref().ok_or(RLibError::DecodingMissingExtraData)?;

        // If we're reading from a file on disk, we require a valid path.
        // If we're reading from a file on memory, we don't need a valid path.
        let disk_file_path = match extra_data.disk_file_path {
            Some(path) => {
                let file_path = PathBuf::from_str(path).map_err(|_|RLibError::DecodingMissingExtraDataField("disk_file_path".to_owned()))?;
                if file_path.is_file() {
                    path.to_owned()
                } else {
                    return Err(RLibError::DecodingMissingExtraData)
                }
            }
            None => String::new()
        };

        let disk_file_offset = extra_data.disk_file_offset;
        let disk_file_size = if extra_data.data_size > 0 { extra_data.data_size } else { data.len()? };
        let timestamp = extra_data.timestamp;
        let is_encrypted = extra_data.is_encrypted;

        // If we don't have a path, or the file is encrypted, we can't lazy-load.
        let lazy_load = !disk_file_path.is_empty() && !is_encrypted && extra_data.lazy_load;

        // First, we do some quick checks to ensure it's a valid Pack.
        // A valid PackFile, bare and empty, needs at least 24 bytes, regardless of game or type.
        let data_len = disk_file_size as u64;
        if data_len < 24 {
            return Err(RLibError::PackFileHeaderNotComplete);
        }

        // Check if it has the weird steam-only header, and skip it if found.
        let start = if data.read_string_u8(3)? == MFH_PREAMBLE { 8 } else { 0 };
        data.seek(SeekFrom::Current(-3))?;
        data.seek(SeekFrom::Current(start))?;

        // Create the default Pack and start populating it.
        let mut pack = Self {
            disk_file_path,
            disk_file_offset,
            local_timestamp: timestamp,
            ..Default::default()
        };

        pack.header.pfh_version = PFHVersion::version(&data.read_string_u8(4)?)?;

        let pack_type = data.read_u32()?;
        pack.header.pfh_file_type = PFHFileType::try_from(pack_type & 15)?;
        pack.header.bitmask = PFHFlags::from_bits_truncate(pack_type & !15);

        // Each Pack version has its own read function, to avoid breaking support for older Packs
        // when implementing support for a new Pack version.
        let expected_data_len = match pack.header.pfh_version {
            PFHVersion::PFH6 => pack.read_pfh6(data, extra_data)?,
            PFHVersion::PFH5 => pack.read_pfh5(data, extra_data)?,
            PFHVersion::PFH4 => pack.read_pfh4(data, extra_data)?,
            PFHVersion::PFH3 => pack.read_pfh3(data, extra_data)?,
            PFHVersion::PFH2 => pack.read_pfh2(data, extra_data)?,
            PFHVersion::PFH0 => pack.read_pfh0(data, extra_data)?,
        };

        // Remove the reserved files from the Pack and read them properly.
        if let Some(mut notes) = pack.files.remove(RESERVED_NAME_NOTES) {
            notes.load()?;
            let data = notes.cached()?;
            let len = data.len();
            let mut data = Cursor::new(data);
            pack.notes = data.read_string_u8(len)?;
        }

        if let Some(mut settings) = pack.files.remove(RESERVED_NAME_SETTINGS) {
            settings.load()?;
            let data = settings.cached()?;
            pack.settings = PackSettings::load(data)?;
        }

        // If at this point we have not reached the end of the PackFile, there is something wrong with it.
        // NOTE: Arena PackFiles have extra data at the end. If we detect one of those PackFiles, take that into account.
        if pack.header.pfh_version == PFHVersion::PFH5 && pack.header.bitmask.contains(PFHFlags::HAS_EXTENDED_HEADER) {
            if expected_data_len + 256 != data_len { return Err(RLibError::DecodingMismatchSizeError(data_len as usize, expected_data_len as usize)) }
        }
        else if expected_data_len != data_len { return Err(RLibError::DecodingMismatchSizeError(data_len as usize, expected_data_len as usize)) }

        // Guess the file's types. Do this here because this can be very slow and here we can do it in paralell.
        pack.files.par_iter_mut().map(|(_, file)| file.guess_file_type()).collect::<Result<()>>()?;

        // If we disabled lazy-loading, load every PackedFile to memory.
        if !lazy_load {
            pack.files.par_iter_mut().try_for_each(|(_, file)| file.load())?;
        }

        // Return our PackFile.
        Ok(pack)
    }

    /// This function writes a `Pack` of version 5 into the provided buffer.
    fn write<W: WriteBytes>(&mut self, buffer: &mut W, extra_data: &Option<EncodeableExtraData>) -> Result<()> {
        let test_mode = if let Some(extra_data) = extra_data {
            extra_data.test_mode
        } else {
            false
        };

        if !test_mode {

            // Only do this in non-vanilla files.
            if self.header.pfh_file_type == PFHFileType::Mod || self.header.pfh_file_type == PFHFileType::Movie {

                // Save notes, if needed.
                if !self.notes.is_empty() {
                    let mut data = vec![];
                    data.write_string_u8(&self.notes)?;
                    let file = RFile::new_from_vec(&data, FileType::Text, 0, RESERVED_NAME_NOTES);
                    self.files.insert(RESERVED_NAME_NOTES.to_owned(), file);
                }

                // Saving PackFile settings.
                let mut data = vec![];
                data.write_all(to_string_pretty(&self.settings)?.as_bytes())?;
                let file = RFile::new_from_vec(&data, FileType::Text, 0, RESERVED_NAME_SETTINGS);
                self.files.insert(RESERVED_NAME_SETTINGS.to_owned(), file);
            }
        }

        match self.header.pfh_version {
            PFHVersion::PFH6 => self.write_pfh6(buffer, extra_data)?,
            PFHVersion::PFH5 => self.write_pfh5(buffer, extra_data)?,
            PFHVersion::PFH4 => self.write_pfh4(buffer, extra_data)?,
            PFHVersion::PFH3 => self.write_pfh3(buffer, extra_data)?,
            PFHVersion::PFH2 => self.write_pfh2(buffer, extra_data)?,
            PFHVersion::PFH0 => self.write_pfh0(buffer, extra_data)?,
        }

        // Remove again the reserved PackedFiles.
        self.remove(&ContainerPath::File(RESERVED_NAME_NOTES.to_owned()));
        self.remove(&ContainerPath::File(RESERVED_NAME_SETTINGS.to_owned()));

        // If nothing has failed, return success.
        Ok(())
    }

    //-----------------------------------------------------------------------//
    //                        Convenience functions
    //-----------------------------------------------------------------------//

    /// This function reads and returns all CA Packs for the provided game merged as one, for easy manipulation.
    ///
    /// This needs a [GameInfo] to get the Packs from, and a game path to search the Packs on.
    pub fn read_and_merge_ca_packs(game: &GameInfo, game_path: &Path) -> Result<Self> {
        let paths = game.ca_packs_paths(game_path)?;
        Self::read_and_merge(&paths, true, true)
    }

    /// Convenience function to open multiple Packs as one, taking care of overwriting files when needed.
    ///
    /// If this function receives only one path, it works as a normal read_from_disk function. If it receives none, an error will be returned.
    pub fn read_and_merge(pack_paths: &[PathBuf], lazy_load: bool, ignore_mods: bool) -> Result<Self> {
        if pack_paths.is_empty() {
            return Err(RLibError::NoPacksProvided);
        }

        let mut extra_data = DecodeableExtraData {
            lazy_load,
            ..Default::default()
        };

        // If we only got one path, just decode the Pack on it.
        if pack_paths.len() == 1 {
            let mut data = BufReader::new(File::open(&pack_paths[0])?);
            let path_str = pack_paths[0].to_string_lossy().to_string();

            extra_data.set_disk_file_path(Some(&path_str));
            extra_data.set_timestamp(last_modified_time_from_file(data.get_ref())?);

            return Self::read(&mut data, &Some(extra_data))
        }

        // Generate a new empty Pack to act as merged one.
        let mut pack_new = Pack::default();
        let mut packs = pack_paths.par_iter()
            .map(|path| {
                let mut data = BufReader::new(File::open(path)?);
                let path_str = path.to_string_lossy().to_string();

                let mut extra_data = extra_data.to_owned();
                extra_data.set_disk_file_path(Some(&path_str));
                extra_data.set_timestamp(last_modified_time_from_file(data.get_ref())?);

                Self::read(&mut data, &Some(extra_data))
            }).collect::<Result<Vec<Pack>>>()?;

        // Sort the decoded Packs by name and type, so each type has their own Packs also sorted by name.
        packs.sort_by_key(|pack| pack.disk_file_path.to_owned());
        packs.sort_by_key(|pack| pack.header.pfh_file_type as u8);

        packs.iter_mut()
            .filter(|pack| {
                if let PFHFileType::Mod = pack.header.pfh_file_type {
                    !ignore_mods
                } else { true }
            })
            .for_each(|pack| {
                pack_new.files_mut().extend(pack.files().clone())
            });

        // Fix the dependencies of the merged pack.
        let pack_names = packs.iter().map(|pack| pack.disk_file_name()).collect::<Vec<_>>();
        let mut dependencies = packs.iter()
            .flat_map(|pack| pack.dependencies()
                .iter()
                .filter(|dependency| !pack_names.contains(dependency))
                .cloned()
                .collect::<Vec<_>>())
            .collect::<Vec<_>>();
        dependencies.sort();
        dependencies.dedup();
        pack_new.set_dependencies(dependencies);

        Ok(pack_new)
    }

    /// Convenience function to easily save a Pack to disk.
    ///
    /// If a path is provided, the Pack will be saved to that path. Otherwise, it'll use whatever path it had set before.
    pub fn save(&mut self, path: Option<&Path>) -> Result<()> {
        if let Some(path) = path {
            self.disk_file_path = path.to_string_lossy().to_string();
        }

        // TODO: Maybe check if the previous path is valid?

        let mut file = BufWriter::new(File::create(&self.disk_file_path)?);
        let extra_data = EncodeableExtraData::default();

        self.encode(&mut file, &Some(extra_data))
    }

    //-----------------------------------------------------------------------//
    //                           Getters & Setters
    //-----------------------------------------------------------------------//

    /// This function returns the current PFH Version of the provided Pack.
    pub fn pfh_version(&self) -> PFHVersion {
        *self.header.pfh_version()
    }

    /// This function returns the current PFH File Type of the provided Pack.
    pub fn pfh_file_type(&self) -> PFHFileType {
        *self.header.pfh_file_type()
    }

    /// This function returns the bitmask applied to the provided Pack.
    pub fn bitmask(&self) -> PFHFlags {
        *self.header.bitmask()
    }

    /// This function returns the timestamp of the last time the Pack was saved.
    pub fn internal_timestamp(&self) -> u64 {
        *self.header.internal_timestamp()
    }

    /// This function returns the Game version this Pack is intended for.
    pub fn game_version(&self) -> u32 {
        *self.header.game_version()
    }

    /// This function returns the build number of the game this Pack is intended for.
    pub fn build_number(&self) -> u32 {
        *self.header.build_number()
    }

    /// This function returns the tool that created the Pack. Max 8 characters, 00-padded.
    pub fn authoring_tool(&self) -> &str {
        self.header.authoring_tool()
    }

    /// This function returns the Extra Subheader Data, if any.
    pub fn extra_subheader_data(&self) -> &[u8] {
        self.header.extra_subheader_data()
    }
/*
    /// This function changes the path of the PackFile.
    ///
    /// This can fail if you pass it an empty path.
    pub fn set_file_path(&mut self, path: &Path) -> Result<()> {
        if path.components().count() == 0 { return Err(ErrorKind::EmptyInput.into()) }
        self.file_path = path.to_path_buf();

        // We have to change the name of the PackFile in all his `PackedFiles` too.
        let file_name = self.disk_file_name();
        self.files.iter_mut().for_each(|x| x.get_ref_mut_raw().set_packfile_name(&file_name));
        Ok(())
    }*/

    /// This function sets the current Pack PFH Version to the provided one.
    pub fn set_pfh_version(&mut self, version: PFHVersion) {
        self.header.set_pfh_version(version);
    }

    /// This function sets the current Pack PFH File Type to the provided one.
    pub fn set_pfh_file_type(&mut self, file_type: PFHFileType) {
        self.header.set_pfh_file_type(file_type);
    }

    /// This function sets the current Pack bitmask to the provided one.
    pub fn set_bitmask(&mut self, bitmask: PFHFlags) {
        self.header.set_bitmask(bitmask);
    }

    /// This function sets the current Pack timestamp to the provided one.
    pub fn set_internal_timestamp(&mut self, timestamp: u64) {
        self.header.set_internal_timestamp(timestamp);
    }

    /// This function sets the game version (as in X.Y.Z) this Pack is for.
    pub fn set_game_version(&mut self, game_version: u32) {
        self.header.set_game_version(game_version);
    }

    /// This function sets the build number this Pack is for.
    pub fn set_build_number(&mut self, build_number: u32) {
        self.header.set_build_number(build_number);
    }

    /// This function sets the authoring tool that last edited this Pack.
    pub fn set_authoring_tool(&mut self, authoring_tool: &str) {
        self.header.set_authoring_tool(authoring_tool.to_string());
    }

    /// This function sets the Extra Subheader Data of the Pack..
    pub fn set_extra_subheader_data(&mut self, extra_subheader_data: &[u8]) {
        self.header.set_extra_subheader_data(extra_subheader_data.to_vec());
    }

    //-----------------------------------------------------------------------//
    //                             Util functions
    //-----------------------------------------------------------------------//

    /// This function returns if the Pack is compressible or not.
    pub fn is_compressible(&self) -> bool {
        matches!(self.header.pfh_version, PFHVersion::PFH6 | PFHVersion::PFH5)
    }

    /// This function is used to generate all loc entries missing from a PackFile into a missing.loc file.
    pub fn generate_missing_loc_data(&mut self) -> Result<Option<ContainerPath>> {

        let db_tables = self.files_by_type(&[FileType::DB]);
        let loc_tables = self.files_by_type(&[FileType::Loc]);
        let mut missing_trads_file = Loc::new(false);

        db_tables.iter().for_each(|rfile| {
            if let RFileDecoded::DB(table) = rfile.decoded().unwrap() {
                let definition = table.definition();
                let fields_processed = definition.fields_processed();
                let localised_fields = definition.localised_fields();
                if !localised_fields.is_empty() && fields_processed.iter().filter(|x| x.is_key()).count() > 1 {
                    println!("{}, keys: {}", table.table_name_without_tables(), fields_processed.iter().filter(|x| x.is_key()).count());
                }
            }
        });

        let loc_keys_from_memory = loc_tables.par_iter().filter_map(|rfile| {
            if let RFileDecoded::Loc(table) = rfile.decoded().unwrap() {
                Some(table.data(&None).unwrap().iter().filter_map(|x| {
                    if let DecodedData::StringU16(data) = &x[0] {
                        Some(data.to_owned())
                    } else {
                        None
                    }
                }).collect::<HashSet<String>>())
            } else { None }
        }).flatten().collect::<HashSet<String>>();

        let missing_trads_file_table_data = db_tables.par_iter().filter_map(|rfile| {
            if let RFileDecoded::DB(table) = rfile.decoded().unwrap() {
                let definition = table.definition();
                let loc_fields = definition.localised_fields();
                let processed_fields = definition.fields_processed();
                if !loc_fields.is_empty() {
                    let table_data = table.data(&None).unwrap();
                    let table_name = table.table_name_without_tables();

                    // Get the keys, which may be concatenated. We get them IN THE ORDER THEY ARE IN THE BINARY FILE.
                    let key_field_names = definition.fields().iter().filter_map(|field| if field.is_key() { Some(field.name()) } else { None }).collect::<Vec<&str>>();
                    let key_field_positions = key_field_names.iter().filter_map(|name| processed_fields.iter().position(|field| field.name() == *name)).collect::<Vec<usize>>();

                    let mut new_rows = vec![];

                    for row in table_data.iter() {
                        for loc_field in loc_fields {
                            let key = key_field_positions.iter().map(|pos| row[*pos].data_to_string()).join("");
                            let loc_key = format!("{}_{}_{}", table_name, loc_field.name(), key);

                            if loc_keys_from_memory.get(&*loc_key).is_none() {
                                let mut new_row = missing_trads_file.new_row();
                                new_row[0] = DecodedData::StringU16(loc_key);
                                new_row[1] = DecodedData::StringU16("PLACEHOLDER".to_owned());
                                new_rows.push(new_row);
                            }
                        }
                    }

                    return Some(new_rows)
                }
            }
            None
        }).flatten().collect::<Vec<Vec<DecodedData>>>();

        // Save the missing translations to a missing_locs.loc file.
        let _ = missing_trads_file.set_data(&missing_trads_file_table_data);
        if !missing_trads_file_table_data.is_empty() {
            let packed_file = RFile::new_from_decoded(&RFileDecoded::Loc(missing_trads_file), 0,  "text/missing_locs.loc");
            Ok(Some(self.insert(packed_file)?))
        } else {
            Ok(None)
        }
    }
}

/*

//---------------------------------------------------------------------------//
//                           Structs Implementations
//---------------------------------------------------------------------------//

/// Implementation of `PackFile`.
impl PackFile {

    /// This function returns if the `PackFile` is editable or not.
    ///
    /// By *if is editable or not* I mean *If you can save it or not*. The conditions under which a PackFile is not editable are:
    /// - All PackFiles with extended header or encrypted parts are not editable.
    /// - All PackFiles of type `Mod` or `Movie` are editable.
    /// - If you say CA PackFiles are not editable:
    ///   - All PackFiles of type `Boot`, `Release` or `Patch` are not editable.
    /// - If you say CA PackFiles are editable:
    ///   - All PackFiles of type `Boot`, `Release` or `Patch` are editable.
    pub fn is_editable(&self, is_editing_of_ca_packfiles_allowed: bool) -> bool {

        // If it's this very specific type, don't save under any circumstance.
        if let PFHFileType::Other(_) = self.pfh_file_type { false }

        // If ANY of these bitmask is detected in the PackFile, disable all saving.
        else if self.bitmask.contains(PFHFlags::HAS_ENCRYPTED_DATA) ||
            self.bitmask.contains(PFHFlags::HAS_ENCRYPTED_INDEX) ||
            self.bitmask.contains(PFHFlags::HAS_EXTENDED_HEADER) { false }
        else {
            self.pfh_file_type == PFHFileType::Mod ||
            self.pfh_file_type == PFHFileType::Movie ||
            (is_editing_of_ca_packfiles_allowed && self.pfh_file_type.get_value() <= 2)
        }
    }

    /// This function returns a copy of the paths of all the `PackedFiles` in the provided `PackFile`.
    pub fn get_packed_files_all_paths(&self) -> Vec<Vec<String>> {
        self.packed_files.par_iter().map(|x| x.get_path().to_vec()).collect()
    }

    /// This function returns a reference of the paths of all the `PackedFiles` in the provided `PackFile`.
    pub fn get_ref_packed_files_all_paths(&self) -> Vec<&[String]> {
        self.packed_files.par_iter().map(|x| x.get_path()).collect()
    }

    /// This function returns a copy of the paths of all the `PackedFiles` in the provided `PackFile` as Strings.
    pub fn get_packed_files_all_paths_as_string(&self) -> HashSet<UniCase<String>> {
        self.packed_files.par_iter().map(|x| UniCase::new(x.get_path().join("/"))).collect()
    }

    /// This function returns a copy of the paths of all the folders in the provided `PackFile` as Strings.
    pub fn get_folder_all_paths_as_string(&self) -> HashSet<UniCase<String>> {
        let mut folder_paths = self.packed_files.par_iter().map(|x| {
            let path = x.get_path();
            let mut paths = Vec::with_capacity(path.len() - 1);

            for (index, folder) in path.iter().enumerate() {
                if index < path.len() - 1 && !folder.is_empty() {
                    paths.push(UniCase::new(path[0..=index].join("/")))
                }
            }

            paths
        }).flatten().collect::<Vec<UniCase<String>>>();

        folder_paths.sort();
        folder_paths.dedup();
        folder_paths.into_iter().collect::<HashSet<_>>()
    }


    /// This function removes, if exists, all `PackedFile` ending with the provided path from the `PackFile`.
    pub fn remove_packed_files_by_path_end(&mut self, path: &[String]) {
        let positions: Vec<usize> = self.packed_files.iter()
            .enumerate()
            .filter(|x| x.1.get_path().ends_with(path) && !path.is_empty())
            .map(|x| x.0)
            .collect();
        for position in positions.iter().rev() {
            self.packed_files.remove(*position);
        }
    }

    /// This function removes, if exists, all `PackedFile` of the provided types from the `PackFile`.
    pub fn remove_packed_files_by_type(&mut self, item_types: &[PathType]) -> Vec<PathType> {

        // We need to "clean" the selected path list to ensure we don't pass stuff already deleted.
        let item_types_clean = PathType::dedup(item_types);

        // Now we do some bitwise magic to get what type of selection combination we have.
        let mut contents: u8 = 0;
        for item_type in &item_types_clean {
            match item_type {
                PathType::File(_) => contents |= 1,
                PathType::Folder(_) => contents |= 2,
                PathType::PackFile => contents |= 4,
                PathType::None => contents |= 8,
            }
        }

        // Then we act, depending on the combination of items.
        match contents {

            // Any combination of files and folders.
            1 | 2 | 3 => {
                for item_type in &item_types_clean {
                    match item_type {
                        PathType::File(path) => self.remove_packed_file_by_path(path),
                        PathType::Folder(path) => self.remove_packed_files_by_path_start(path),
                        _ => unreachable!(),
                    }
                }
            },

            // If the `PackFile` is selected, just delete everything.
            4 | 5 | 6 | 7 => self.remove_all_packedfiles(),

            // No paths selected, none selected, invalid path selected, or invalid value.
            0 | 8..=255 => {},
        }

        // Return the list of deleted items so the caller can have a clean list to know what was really removed from the `PackFile`.
        item_types_clean
    }

    /// This function extract, if exists, all `PackedFile` of the provided types from the `PackFile` to disk.
    ///
    /// As this can fail for some files, and work for others, we return `Ok(amount_files_extracted)` only if all files were extracted correctly.
    /// If any of them failed, we return `Error` with a list of the paths that failed to get extracted.
    pub fn extract_packed_files_by_type(
        &mut self,
        item_types: &[PathType],
        extracted_path: &Path,
        extract_table_as_tsv: bool
    ) -> Result<u32> {

        // These variables are here to keep track of what we have extracted and what files failed.
        let mut files_extracted = 0;
        let mut error_files = vec![];

        // We need to "clean" the selected path list to ensure we don't pass stuff already extracted.
        let item_types_clean = PathType::dedup(item_types);

        // Now we do some bitwise magic to get what type of selection combination we have.
        let mut contents: u8 = 0;
        for item_type in &item_types_clean {
            match item_type {
                PathType::File(_) => contents |= 1,
                PathType::Folder(_) => contents |= 2,
                PathType::PackFile => contents |= 4,
                PathType::None => contents |= 8,
            }
        }

        // Then we act, depending on the combination of items.
        match contents {

            // Any combination of files and folders.
            1 | 2 | 3 => {

                // For folders we check each PackedFile to see if it starts with the folder's path (it's in the folder).
                // There should be no duplicates here thanks to the filters from before.
                for item_type in &item_types_clean {
                    match item_type {

                        // For individual `PackedFiles`, we extract them one by one.
                        PathType::File(path) => {
                            match self.extract_packed_file_by_path(path, extracted_path, extract_table_as_tsv) {
                                Ok(_) => files_extracted += 1,
                                Err(_) => error_files.push(format!("{:?}", path)),
                            }
                        },

                        PathType::Folder(path) => {
                            for packed_file in self.get_ref_mut_packed_files_by_path_start(path) {
                                match packed_file.extract_packed_file(extracted_path, extract_table_as_tsv) {
                                    Ok(_) => files_extracted += 1,
                                    Err(_) => error_files.push(format!("{:?}", path)),
                                }
                            }
                        },

                        _ => unreachable!(),
                    }
                }
            },

            // If the `PackFile` is selected, just extract it and everything will get extracted with it.
            4 | 5 | 6 | 7 => {

                // For each PackedFile we have, just extracted in the folder we got, under the PackFile's folder.
                let mut packed_files = self.get_ref_mut_packed_files_all();
                files_extracted = packed_files.len() as u32;

                error_files = packed_files.par_iter_mut().filter_map(|packed_file| {
                    if packed_file.extract_packed_file(extracted_path, extract_table_as_tsv).is_err() {
                        Some(format!("{:?}", packed_file.get_path()))
                    } else { None }
                }).collect();
                files_extracted -= error_files.len() as u32;

                // If we're extracting everything as TSV, it's a mymod export. Also extract notes and settings.
                if extract_table_as_tsv {

                    if let Some(note) = &self.notes {
                        let mut data = vec![];
                        data.encode_string_u8(note);
                        let path = extracted_path.join(RESERVED_NAME_NOTES.to_owned() + ".md");
                        let mut file = BufWriter::new(File::create(path)?);
                        file.write_all(&data)?;
                        file.flush()?;
                    }

                    // Saving PackFile settings.
                    let mut data = vec![];
                    data.write_all(to_string_pretty(&self.settings)?.as_bytes())?;
                    data.extend_from_slice(b"\n"); // Add newline to the end of the file
                    let path = extracted_path.join(RESERVED_NAME_SETTINGS.to_owned() + ".json");
                    let mut file = BufWriter::new(File::create(path)?);
                    file.write_all(&data)?;
                    file.flush()?;
                }
            },

            // No paths selected, none selected, invalid path selected, or invalid value.
            0 | 8..=255 => return Err(ErrorKind::NonExistentFile.into()),
        }

        // If there is any error in the list, report it.
        if !error_files.is_empty() {
            let error_files_string = error_files.iter().map(|x| format!("<li>{}</li>", x)).collect::<Vec<String>>();
            return Err(ErrorKind::ExtractError(error_files_string).into())
        }

        // If we reach this, return the amount of extracted files.
        Ok(files_extracted)
    }

    /// This function is used to patch Warhammer Siege map packs so their AI actually works.
    ///
    /// This also removes the useless xml files left by Terry in the `PackFile`.
    pub fn patch_siege_ai(&mut self) -> Result<(String, Vec<Vec<String>>)> {

        // If there are no files, directly return an error.
        if self.packed_files.is_empty() {
            return Err(ErrorKind::PatchSiegeAIEmptyPackFile.into())
        }

        let mut files_patched = 0;
        let mut files_to_delete: Vec<Vec<String>> = vec![];
        let mut multiple_defensive_hill_hints = false;

        // We only need to change stuff inside the map folder, so we only check the maps in that folder.
        for packed_file in self.get_ref_mut_packed_files_by_path_start(&Self::get_terry_map_path()) {
            let path = packed_file.get_path();
            let name = path.last().unwrap().clone();

            // The files we need to process are `bmd_data.bin` and all the `catchment_` files the map has.
            if name == DEFAULT_BMD_DATA || (name.starts_with("catchment_") && name.ends_with(".bin")) {
                let data = packed_file.get_ref_mut_raw().get_ref_mut_data_and_keep_it()?;

                // The patching process it's simple. First, we check if there is SiegeAI stuff in the file by checking if there is an Area Node.
                // If we find one, we check if there is a defensive hill hint in the same file, and patch it if there is one.
                if data.windows(19).any(|window: &[u8]|window == SIEGE_AREA_NODE_HINT) {
                    if let Some(index) = data.windows(18).position(|window: &[u8]|window == DEFENSIVE_HILL_HINT) {
                        data.splice(index..index + 18, FORT_PERIMETER_HINT.iter().cloned());
                        files_patched += 1;
                    }

                    // If there is more than one defensive hill in one file, is a valid file, but we want to warn the user about it.
                    if data.windows(18).any(|window: &[u8]|window == DEFENSIVE_HILL_HINT) {
                        multiple_defensive_hill_hints = true;
                    }
                }
            }

            // All xml in this folder are useless, so we mark them all for deletion.
            else if name.ends_with(".xml") {
                files_to_delete.push(packed_file.get_path().to_vec());
            }
        }

        // If there are files to delete, we delete them.
        files_to_delete.iter().for_each(|x| self.remove_packed_file_by_path(x));

        // If we didn't found any file to patch or delete, return an error.
        if files_patched == 0 && files_to_delete.is_empty() { Err(ErrorKind::PatchSiegeAINoPatchableFiles.into()) }

        // TODO: make this more.... `fluent`.
        // If we found files to delete, but not to patch, return a message reporting it.
        else if files_patched == 0 {
            Ok((format!("No file suitable for patching has been found.\n{} files deleted.", files_to_delete.len()), files_to_delete))
        }

        // If we found multiple defensive hill hints... it's ok, but we return a warning.
        else if multiple_defensive_hill_hints {

            // The message is different depending on the amount of files deleted.
            if files_to_delete.is_empty() {
                Ok((format!("{} files patched.\nNo file suitable for deleting has been found.\
                \n\n\
                WARNING: Multiple Defensive Hints have been found and we only patched the first one.\
                 If you are using SiegeAI, you should only have one Defensive Hill in the map (the \
                 one acting as the perimeter of your fort/city/castle). Due to SiegeAI being present, \
                 in the map, normal Defensive Hills will not work anyways, and the only thing they do \
                 is interfere with the patching process. So, if your map doesn't work properly after \
                 patching, delete all the extra Defensive Hill Hints. They are the culprit.",
                 files_patched), files_to_delete))
            }
            else {
                Ok((format!("{} files patched.\n{} files deleted.\
                \n\n\
                WARNING: Multiple Defensive Hints have been found and we only patched the first one.\
                 If you are using SiegeAI, you should only have one Defensive Hill in the map (the \
                 one acting as the perimeter of your fort/city/castle). Due to SiegeAI being present, \
                 in the map, normal Defensive Hills will not work anyways, and the only thing they do \
                 is interfere with the patching process. So, if your map doesn't work properly after \
                 patching, delete all the extra Defensive Hill Hints. They are the culprit.",
                files_patched, files_to_delete.len()), files_to_delete))
            }
        }

        // If no files to delete were found, but we got files patched, report it.
        else if files_to_delete.is_empty() {
            Ok((format!("{} files patched.\nNo file suitable for deleting has been found.", files_patched), files_to_delete))
        }

        // And finally, if we got some files patched and some deleted, report it too.
        else {
            Ok((format!("{} files patched.\n{} files deleted.", files_patched, files_to_delete.len()), files_to_delete))
        }
    }

*/
/// Implementation of PackFileSettings.
impl PackSettings {

    /// This function tries to load the settings from the current PackFile and return them.
    pub fn load(data: &[u8]) -> Result<Self> {
        from_slice(data).map_err(From::from)
    }

    pub fn diagnostics_files_to_ignore(&self) -> Option<Vec<(String, Vec<String>, Vec<String>)>> {
        self.settings_text.get("diagnostics_files_to_ignore").map(|files_to_ignore| {
            let files = files_to_ignore.split('\n').collect::<Vec<&str>>();

            // Ignore commented out rows.
            files.iter().filter_map(|x| {
                if !x.starts_with('#') {
                    let path = x.splitn(3, ';').collect::<Vec<&str>>();
                    if path.len() == 3 {
                        Some((path[0].to_string(), path[1].split(',').filter_map(|y| if !y.is_empty() { Some(y.to_owned()) } else { None }).collect::<Vec<String>>(), path[2].split(',').filter_map(|y| if !y.is_empty() { Some(y.to_owned()) } else { None }).collect::<Vec<String>>()))
                    } else if path.len() == 2 {
                        Some((path[0].to_string(), path[1].split(',').filter_map(|y| if !y.is_empty() { Some(y.to_owned()) } else { None }).collect::<Vec<String>>(), vec![]))
                    } else if path.len() == 1 {
                        Some((path[0].to_string(), vec![], vec![]))
                    } else {
                        None
                    }
                } else {
                    None
                }
            }).collect::<Vec<(String, Vec<String>, Vec<String>)>>()
        })
    }
}


/// Implementation of trait `Default` for `PFHFlags`.
impl Default for PFHFlags {
    fn default() -> Self {
        Self::empty()
    }
}
